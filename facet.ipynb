{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import xml.etree.cElementTree as ET\n",
    "import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def to_normal(a1):\n",
    "    a1 = re.sub(r'\\d+', '', a1)\n",
    "    a1 = re.sub(r'[^\\w\\s]','',a1)\n",
    "    a1 = re.sub('\\n', '', a1)\n",
    "    a1 = a1.strip()\n",
    "    a1 = a1.lower()\n",
    "    \n",
    "    #print a1\n",
    "    return a1\n",
    "\n",
    "def find_match(a1,a2):    \n",
    "    a1 = to_normal(a1)\n",
    "    dis = 1\n",
    "    paper = None\n",
    "    for elem in a2:\n",
    "        \n",
    "        score = distance.nlevenshtein(a1, elem)\n",
    "        #print 'comparing: \\n'+ a1 +'\\n'+ elem\n",
    "        #print score\n",
    "        if score<dis:\n",
    "            paper = elem\n",
    "            dis = score\n",
    "    if dis<0.1:\n",
    "        return paper\n",
    "\n",
    "    #for elem in a2:\n",
    "        #elem = to_normal(elem)   \n",
    "    #print fuzz.token_set_ratio(a1,a2)\n",
    "    #print process.extractOne(a1, [a2])\n",
    "        #return process.extractOne(a1, a2)[0]\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading data\n",
    "network = pd.read_csv(\"network.csv\")\n",
    "\n",
    "#Creating incite and outcite dictionary\n",
    "incite = {}\n",
    "outcite = {}\n",
    "for row in network.iterrows():\n",
    "    if(type(row[1][1])!=str):\n",
    "        incite[row[1][0]] = []\n",
    "    else:\n",
    "        incite[row[1][0]] = row[1][1].split(',')\n",
    "    if(type(row[1][2])!=str):\n",
    "        outcite[row[1][0]] = []\n",
    "    else:\n",
    "        outcite[row[1][0]] = row[1][2].split(',')\n",
    "\n",
    "paper_directory = \"../2014/papers_text\"\n",
    "\n",
    "#paper_array = names of all papers in dataset ordered lexically\n",
    "paper_array = []\n",
    "for filename in os.listdir(paper_directory):\n",
    "    if filename.endswith(\".txt\"): \n",
    "        #print(os.path.join(directory, filename))\n",
    "        paper_array.append(filename[:-4])\n",
    "paper_array = sorted(paper_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcite_1 = {}\n",
    "incite_1 = {}\n",
    "for paper_id in paper_array[:50]:\n",
    "    incite_1[paper_id] = []\n",
    "    outcite_1[paper_id] = []\n",
    "\n",
    "paper_ids=open(\"../2014/paper_ids.txt\",\"r\")\n",
    "dict_id={}\n",
    "for line in paper_ids:\n",
    "    key=line[:8]\n",
    "    value=to_normal(line[9:-5].strip())\n",
    "    dict_id[key]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for curr_paper in outcite_1.keys():\n",
    "    \n",
    "    tree = ET.ElementTree(file= '../data/xml/A/A00/'+curr_paper+'-parscit.130908'+'.xml')\n",
    "    root = tree.getroot()\n",
    "\n",
    "    heading = []\n",
    "    body = []\n",
    "    count = -1\n",
    "    for elem in root[0][0]:\n",
    "        count+=1\n",
    "        if elem.tag == 'sectionHeader' or elem.tag =='subsectionHeader':\n",
    "            heading.append([count, elem.text])\n",
    "        if elem.tag == 'bodyText':\n",
    "            body.append([count, elem.text])\n",
    "        \n",
    "#print heading[:9]\n",
    "#print body[1][1]\n",
    "\n",
    "    cit_head_map = {}\n",
    "    for elem in tree.iter(tag='citation'):\n",
    "        heads_ind = []\n",
    "        citstr = []\n",
    "        title = []\n",
    "        body_ind = []\n",
    "        for child in elem:\n",
    "            if child.tag == 'title':\n",
    "                title = child.text       \n",
    "            if child.tag == 'contexts':            \n",
    "                citstr = child[0].attrib['citStr']\n",
    "            \n",
    "        if (citstr == []) or (title == []):\n",
    "            continue\n",
    "        else:\n",
    "        #print 'title: '+ title\n",
    "        #print 'citStr: '+ citstr\n",
    "    \n",
    "            for entry in body:\n",
    "                if citstr in entry[1]:\n",
    "                    body_ind.append(entry[0])\n",
    "            \n",
    "            if len(body_ind)!=0:\n",
    "                for ind in body_ind:\n",
    "                    #print 'body: '+ str(ind)\n",
    "                    sect_ind = -1\n",
    "                    for entry in heading:\n",
    "                        if entry[0]<ind and entry[0]>sect_ind:\n",
    "                            sect_ind = entry[0]\n",
    "                    #print sect_ind\n",
    "                    sect = root[0][0][sect_ind].text\n",
    "                    sect = to_normal(sect)\n",
    "                    #print 'sect:'+ sect\n",
    "                    cit_head_map[to_normal(title)]=sect.strip()\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    for entry in outcite[curr_paper]:\n",
    "        #print entry\n",
    "        matched = find_match(dict_id[entry],cit_head_map.keys())\n",
    "        if matched:\n",
    "            #print 'match_found !'\n",
    "            outcite_1[curr_paper].append([entry,cit_head_map[matched]])                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"dict.txt\", \"wb\") as dict_file:\n",
    "    pickle.dump(outcite_1, dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result for A00-1001 ---to--- A00-1010  for analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A00-1010\n",
      "['H94-1010', 'P96-1008', 'W00-0303']\n",
      "A00-1009\n",
      "['A92-1006', 'A97-1037', 'A97-1039', 'C92-3158', 'J85-1003', 'J94-4004']\n",
      "A00-1008\n",
      "['A00-2041', 'J86-3001', 'P98-1059']\n",
      "A00-1001\n",
      "['J82-3002']\n",
      "A00-1003\n",
      "['P98-1066', 'P99-1027', 'P99-1029']\n",
      "A00-1002\n",
      "['C90-3057', 'P98-1080']\n",
      "A00-1005\n",
      "['J86-3001', 'J99-3003', 'P96-1009']\n",
      "A00-1004\n",
      "['A00-1019', 'J93-1006', 'J93-2003', 'P91-1022', 'P91-1023', 'P93-1002', 'P94-1012']\n",
      "A00-1007\n",
      "['J96-2004']\n",
      "A00-1006\n",
      "['C96-1070', 'P98-2131', 'P98-2185', 'W97-0403']\n"
     ]
    }
   ],
   "source": [
    "for key in outcite_1.keys():\n",
    "    print key\n",
    "    print outcite[key]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A00-1001': [['J82-3002', 'previous efforts chatprat and hsql']],\n",
       " 'A00-1002': [],\n",
       " 'A00-1003': [['P98-1066', 'evaluation']],\n",
       " 'A00-1004': [['A00-1019', 'introduction'],\n",
       "  ['P91-1022', 'parallel text alignment'],\n",
       "  ['P93-1002', 'parallel text alignment'],\n",
       "  ['P94-1012', 'parallel text alignment']],\n",
       " 'A00-1005': [['J99-3003', 'previous work']],\n",
       " 'A00-1006': [['C96-1070', 'transfer driven machinetranslation'],\n",
       "  ['W97-0403', 'introduction']],\n",
       " 'A00-1007': [],\n",
       " 'A00-1008': [],\n",
       " 'A00-1009': [['A92-1006',\n",
       "   'history of the framework and comparisonwith other systems'],\n",
       "  ['A97-1037', 'history of the framework and comparisonwith other systems'],\n",
       "  ['A97-1039', 'history of the framework and comparisonwith other systems'],\n",
       "  ['C92-3158', 'history of the framework and comparisonwith other systems'],\n",
       "  ['J85-1003', 'introduction'],\n",
       "  ['J94-4004', 'the frameworks linguistic resources']],\n",
       " 'A00-1010': []}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcite_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to load the dict_file use pickle:\n",
    "\n",
    "#import pickle\n",
    "#with open(\"dict.txt\", \"rb\") as dict_file:\n",
    "#    out_1 = pickle.load(dict_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
